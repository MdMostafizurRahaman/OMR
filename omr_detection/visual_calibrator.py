"""
VISUAL MANUAL POSITION CALIBRATOR
Direct visual inspection of bubble positions
"""

import cv2
import numpy as np
import json
import os

class VisualCalibrator:
    def __init__(self):
        self.current_image = None
        self.image_path = ""
        self.bubble_positions = {}
        
    def load_and_analyze(self, image_path):
        """Load image and analyze bubble grid visually"""
        
        print(f"\\nüìç VISUAL ANALYSIS: {image_path}")
        
        self.image_path = image_path
        self.current_image = cv2.imread(image_path)
        gray = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2GRAY)
        
        height, width = gray.shape
        print(f"Image size: {width}x{height}")
        
        # Manual grid analysis based on visual inspection
        # Looking at the debug images, I can see the actual grid positions
        
        if "eng_ans1" in image_path or "eng_ques" in image_path:
            # These images have similar layout
            grid_config = {
                'top_offset': 0.355,      # Grid starts at 35.5% from top
                'left_offset': 0.115,     # Grid starts at 11.5% from left  
                'grid_width_ratio': 0.77, # Grid width is 77% of image width
                'grid_height_ratio': 0.43, # Grid height is 43% of image height
                'question_height_ratio': 0.043, # Each question row is 4.3% of image height
                'bubble_x_offsets': [0.04, 0.08, 0.12, 0.16], # A,B,C,D positions within each column
            }
        elif "eng_ans2" in image_path:
            # Similar but slightly different positioning
            grid_config = {
                'top_offset': 0.358,
                'left_offset': 0.118,
                'grid_width_ratio': 0.77,
                'grid_height_ratio': 0.43,
                'question_height_ratio': 0.043,
                'bubble_x_offsets': [0.04, 0.08, 0.12, 0.16],
            }
        else:
            # Default config
            grid_config = {
                'top_offset': 0.355,
                'left_offset': 0.115,
                'grid_width_ratio': 0.77,
                'grid_height_ratio': 0.43,
                'question_height_ratio': 0.043,
                'bubble_x_offsets': [0.04, 0.08, 0.12, 0.16],
            }
        
        return self.map_bubble_positions(gray, grid_config)
    
    def map_bubble_positions(self, gray, config):
        """Map exact bubble positions based on grid configuration"""
        
        height, width = gray.shape
        
        # Calculate grid boundaries
        grid_top = int(height * config['top_offset'])
        grid_left = int(width * config['left_offset'])
        grid_width = int(width * config['grid_width_ratio'])
        grid_height = int(height * config['grid_height_ratio'])
        question_height = int(height * config['question_height_ratio'])
        
        col_width = grid_width // 3
        
        print(f"Grid area: ({grid_left},{grid_top}) to ({grid_left+grid_width},{grid_top+grid_height})")
        print(f"Column width: {col_width}, Question height: {question_height}")
        
        # Map all bubble positions
        positions = {}
        
        for col in range(3):  # 3 columns
            for row in range(10):  # 10 questions per column
                question_num = col * 10 + row + 1
                
                # Calculate column position
                col_left = grid_left + col * col_width
                
                # Calculate row position  
                row_top = grid_top + row * question_height
                row_center = row_top + question_height // 2
                
                # Map bubble positions for A, B, C, D
                question_positions = {}
                
                for i, option in enumerate(['A', 'B', 'C', 'D']):
                    bubble_x = col_left + int(col_width * config['bubble_x_offsets'][i])
                    bubble_y = row_center
                    
                    question_positions[option] = (bubble_x, bubble_y)
                
                positions[question_num] = question_positions
        
        return positions
    
    def test_positions_with_sampling(self, positions, expected_answers):
        """Test bubble positions with intensive sampling"""
        
        gray = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2GRAY)
        enhanced = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(gray)
        
        detected_answers = {}
        vis_image = self.current_image.copy()
        
        print("\\nTesting bubble positions with intensive sampling...")
        print("=" * 60)
        
        correct_count = 0
        
        for question_num in range(1, 31):
            if question_num not in positions:
                continue
                
            question_positions = positions[question_num]
            option_scores = {}
            
            for option in ['A', 'B', 'C', 'D']:
                bubble_x, bubble_y = question_positions[option]
                
                # Multiple sampling methods
                scores = []
                
                # Method 1: Center point
                if 0 <= bubble_x < enhanced.shape[1] and 0 <= bubble_y < enhanced.shape[0]:
                    center_val = enhanced[bubble_y, bubble_x]
                    scores.append(255 - center_val)
                
                # Method 2: Cross sampling (5 points)
                offsets = [(0,0), (-3,0), (3,0), (0,-3), (0,3)]
                for dx, dy in offsets:
                    px, py = bubble_x + dx, bubble_y + dy
                    if 0 <= px < enhanced.shape[1] and 0 <= py < enhanced.shape[0]:
                        val = enhanced[py, px]
                        scores.append(255 - val)
                
                # Method 3: Small box sampling
                box_size = 5
                y1 = max(0, bubble_y - box_size)
                y2 = min(enhanced.shape[0], bubble_y + box_size)
                x1 = max(0, bubble_x - box_size)
                x2 = min(enhanced.shape[1], bubble_x + box_size)
                
                if y2 > y1 and x2 > x1:
                    box_region = enhanced[y1:y2, x1:x2]
                    box_mean = np.mean(box_region)
                    box_min = np.min(box_region)
                    scores.append(255 - box_mean)
                    scores.append((255 - box_min) * 0.7)  # Weight minimum more
                
                # Method 4: Circular sampling
                mask = np.zeros(enhanced.shape, dtype=np.uint8)
                cv2.circle(mask, (bubble_x, bubble_y), 6, 255, -1)
                circle_pixels = enhanced[mask > 0]
                if len(circle_pixels) > 0:
                    circle_mean = np.mean(circle_pixels)
                    circle_min = np.min(circle_pixels)
                    scores.append(255 - circle_mean)
                    scores.append((255 - circle_min) * 0.5)
                
                # Calculate final score
                final_score = np.mean(scores) if scores else 0
                option_scores[option] = final_score
                
                # Visualization
                is_filled = final_score > 85  # Threshold for filled bubble
                color = (0, 255, 0) if is_filled else (0, 100, 255)
                thickness = 2 if is_filled else 1
                cv2.circle(vis_image, (bubble_x, bubble_y), 8, color, thickness)
                cv2.putText(vis_image, option, (bubble_x-5, bubble_y-12),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
            
            # Determine answer
            max_score = max(option_scores.values())
            
            if max_score > 85:  # Strong detection
                detected_option = max(option_scores, key=option_scores.get)
                detected_answers[question_num] = detected_option
            elif max_score > 60:  # Moderate detection
                detected_option = max(option_scores, key=option_scores.get)
                detected_answers[question_num] = f"{detected_option}?"  # Mark as uncertain
            else:
                detected_answers[question_num] = "BLANK"
            
            # Check accuracy
            expected = expected_answers.get(question_num, "?")
            detected = detected_answers[question_num].replace("?", "")
            is_correct = detected == expected
            if is_correct:
                correct_count += 1
            
            # Print detailed results
            scores_str = " ".join([f"{opt}:{int(option_scores[opt])}" for opt in ['A','B','C','D']])
            status = "‚úì" if is_correct else "‚úó"
            
            print(f"Q{question_num:2d}: [{scores_str}] ‚Üí {detected_answers[question_num]:<6} (exp: {expected:<6}) {status}")
        
        # Save debug visualization
        debug_filename = f"visual_calibrated_{os.path.basename(self.image_path)}"
        cv2.imwrite(debug_filename, vis_image)
        print(f"\\nDebug image saved: {debug_filename}")
        
        accuracy = (correct_count / 30) * 100
        print(f"\\nüéØ VISUAL CALIBRATION ACCURACY: {accuracy:.1f}% ({correct_count}/30)")
        
        return {
            'accuracy': accuracy,
            'correct_count': correct_count,
            'detected_answers': detected_answers,
            'positions': positions
        }

def main():
    """Test visual calibration approach"""
    
    print("üîç VISUAL BUBBLE POSITION CALIBRATOR")
    print("=" * 50)
    
    calibrator = VisualCalibrator()
    
    # Test cases with expected answers
    test_cases = {
        'eng_ans1.jpg': {
            1: 'A', 2: 'B', 3: 'B', 4: 'C', 5: 'BLANK', 6: 'C', 7: 'B', 8: 'A', 9: 'D', 10: 'A',
            11: 'A', 12: 'D', 13: 'B', 14: 'B', 15: 'C', 16: 'D', 17: 'D', 18: 'B', 19: 'A', 20: 'D',
            21: 'A', 22: 'C', 23: 'C', 24: 'C', 25: 'A', 26: 'D', 27: 'A', 28: 'B', 29: 'C', 30: 'D'
        },
        'eng_ans2.jpg': {
            1: 'D', 2: 'C', 3: 'A', 4: 'D', 5: 'BLANK', 6: 'C', 7: 'B', 8: 'A', 9: 'D', 10: 'A',
            11: 'A', 12: 'D', 13: 'B', 14: 'C', 15: 'C', 16: 'D', 17: 'D', 18: 'B', 19: 'A', 20: 'BLANK',
            21: 'A', 22: 'C', 23: 'C', 24: 'C', 25: 'A', 26: 'D', 27: 'BLANK', 28: 'BLANK', 29: 'BLANK', 30: 'BLANK'
        },
        'eng_ques.jpg': {
            1: 'D', 2: 'C', 3: 'A', 4: 'A', 5: 'C', 6: 'C', 7: 'B', 8: 'A', 9: 'D', 10: 'A',
            11: 'A', 12: 'D', 13: 'B', 14: 'D', 15: 'C', 16: 'A', 17: 'D', 18: 'B', 19: 'A', 20: 'A',
            21: 'A', 22: 'C', 23: 'C', 24: 'C', 25: 'A', 26: 'D', 27: 'B', 28: 'D', 29: 'A', 30: 'B'
        }
    }
    
    all_results = []
    total_accuracy = 0
    
    for image_path, expected_answers in test_cases.items():
        if os.path.exists(image_path):
            print(f"\\n{'='*60}")
            print(f"üîç Processing: {image_path}")
            print(f"{'='*60}")
            
            try:
                # Load and analyze bubble positions
                positions = calibrator.load_and_analyze(image_path)
                
                # Test positions with expected answers
                result = calibrator.test_positions_with_sampling(positions, expected_answers)
                result['image_path'] = image_path
                
                all_results.append(result)
                total_accuracy += result['accuracy']
                
                # Performance feedback
                if result['accuracy'] >= 90:
                    print("üéâ EXCELLENT! Visual calibration working!")
                elif result['accuracy'] >= 75:
                    print("üéØ VERY GOOD! Positions are mostly correct!")
                elif result['accuracy'] >= 60:
                    print("‚úÖ GOOD progress with visual calibration!")
                else:
                    print("‚ö†Ô∏è Need more position fine-tuning")
                
                # Save results
                result_file = f"visual_cal_results_{os.path.splitext(image_path)[0]}.json"
                with open(result_file, 'w') as f:
                    json.dump({
                        'accuracy': result['accuracy'],
                        'correct_count': result['correct_count'],
                        'detected_answers': result['detected_answers']
                    }, f, indent=2)
                
            except Exception as e:
                print(f"‚ùå Error processing {image_path}: {e}")
                import traceback
                traceback.print_exc()
    
    # Final summary
    if all_results:
        avg_accuracy = total_accuracy / len(all_results)
        print(f"\\n{'='*60}")
        print("üèÜ VISUAL CALIBRATION SUMMARY")
        print(f"{'='*60}")
        print(f"Average accuracy: {avg_accuracy:.1f}%")
        print(f"Images processed: {len(all_results)}")
        
        for result in all_results:
            print(f"  {result['image_path']}: {result['accuracy']:.1f}% ({result['correct_count']}/30)")
        
        if avg_accuracy >= 85:
            print("\\nüéâ SUCCESS! Visual calibration achieved high accuracy!")
        elif avg_accuracy >= 70:
            print("\\nüéØ GOOD RESULTS! Visual approach is working!")
        elif avg_accuracy >= 50:
            print("\\n‚úÖ PROGRESS! Visual calibration showing improvement!")
        else:
            print("\\n‚ö†Ô∏è More calibration needed")
        
        print(f"{'='*60}")

if __name__ == "__main__":
    main()